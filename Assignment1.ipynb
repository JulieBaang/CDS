{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your own concordance\n",
    "\n",
    "It took 500 Dominican munks to write the first concordance of the Latin bible, and it took Rabbi Mordecai Nathan 10 years to write the first concordance of the Hebrew bible. With Python, it only takes a matter of seconds to find words in a text, along with the surrounding words.\n",
    "\n",
    "Run each cell in this notebook one at a time, in order. If something in one cell doesn't work right, it might be because you have overwritten a variable, so try going back and running all the previous cells again.\n",
    "\n",
    "First run the code and check that everything works. Then, try modifying the code. Start with the first challenges, and then continue in order. Feel free to work together, and see how far you can get. The important thing is to learn, not to solve all the challenges!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the natural language toolkit package (nltk), which has a copy of several texts, \n",
    "#including the King James Bible\n",
    "\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the nltk package so that it is accessible to Python, and download a collection of texts from Project Gutenberg\n",
    "import nltk\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable called \"bible\" which contains the text of the King James bible.\n",
    "bible = nltk.corpus.gutenberg.raw('bible-kjv.txt')\n",
    "\n",
    "# make all characters lowercase\n",
    "bible = bible.lower()\n",
    "\n",
    "# remove the \"\\n\" characters, which indicate line breaks in the text (newlines)\n",
    "bible = bible.replace('\\n', ' ')\n",
    "\n",
    "# split up the text into a long list of individual words\n",
    "bible = bible.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a variable called \"concordance\", and fill it with every occurrence of the phrase \"this world\", and a few words preceeding and following \"this world\"\n",
    "concordance = []\n",
    "for i, val in enumerate(bible):\n",
    "    if val == \"world\":\n",
    "        if bible[i-1] == \"this\":\n",
    "            concordance.append(str(' '.join(bible[i-5:i+5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['for the children of this world are in their generation',\n",
       " 'them, the children of this world marry, and are given',\n",
       " 'hateth his life in this world shall keep it unto',\n",
       " 'shall the prince of this world be cast out. ',\n",
       " 'should depart out of this world unto the father, having',\n",
       " 'for the prince of this world cometh, and hath nothing',\n",
       " 'because the prince of this world is judged.  16:12',\n",
       " 'of the princes of this world knew: for had they',\n",
       " 'for the wisdom of this world is foolishness with god.',\n",
       " 'for the fashion of this world passeth away.  7:32',\n",
       " 'whom the god of this world hath blinded the minds',\n",
       " 'chosen the poor of this world rich in faith, and',\n",
       " 'saying, the kingdoms of this world are become the kingdoms']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at what the algorithm has found\n",
    "concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how many instances of the phrase \"this world\" were found\n",
    "len(concordance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try again, but this time let's just search for \"world\" by itself, not \"this world\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "concordance = []\n",
    "for i, val in enumerate(bible):\n",
    "    if val == \"world\":\n",
    "        concordance.append(str(' '.join(bible[i-5:i+5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and he hath set the world upon them.  2:9',\n",
       " 'appeared, the foundations of the world were discovered, at the',\n",
       " 'him, all the earth: the world also shall be stable,',\n",
       " 'upon the face of the world in the earth. ',\n",
       " 'and he shall judge the world in righteousness, he shall',\n",
       " 'and the foundations of the world were discovered at thy',\n",
       " 'all the ends of the world shall remember and turn',\n",
       " 'all the inhabitants of the world stand in awe of',\n",
       " 'not tell thee: for the world is mine, and the',\n",
       " 'is thine: as for the world and the fulness thereof,',\n",
       " 'he hath girded himself: the world also is stablished, that',\n",
       " 'that the lord reigneth: the world also shall be established',\n",
       " 'earth: he shall judge the world with righteousness, and the',\n",
       " 'also he hath set the world in their heart, so',\n",
       " 'and i will punish the world for their evil, and',\n",
       " 'kingdoms; 14:17 that made the world as a wilderness, and',\n",
       " 'fill the face of the world with cities.  14:22',\n",
       " 'all the kingdoms of the world upon the face of',\n",
       " 'mourneth and fadeth away, the world languisheth and fadeth away,',\n",
       " 'earth, the inhabitants of the world will learn righteousness. ',\n",
       " 'have the inhabitants of the world fallen.  26:19 thy',\n",
       " 'fill the face of the world with fruit.  27:7',\n",
       " 'not be ashamed nor confounded world without end.  45:18',\n",
       " 'since the beginning of the world men have not heard,',\n",
       " 'power, he hath established the world by his wisdom, and',\n",
       " 'power, he hath established the world by his wisdom, and',\n",
       " 'this world, neither in the world to come.  12:33',\n",
       " ' 18:7 woe unto the world because of offences! for',\n",
       " 'be preached in all the world for a witness unto',\n",
       " 'since the beginning of the world to this time, no,',\n",
       " 'with persecutions; and in the world to come eternal life.',\n",
       " 'which have been since the world began: 1:71 that we',\n",
       " 'caesar augustus that all the world should be taxed. ',\n",
       " 'all the kingdoms of the world in a moment of',\n",
       " 'do the nations of the world seek after: and your',\n",
       " 'for the children of this world are in their generation',\n",
       " 'present time, and in the world to come life everlasting.',\n",
       " 'them, the children of this world marry, and are given',\n",
       " 'in the world, and the world was made by him,',\n",
       " 'made by him, and the world knew him not. ',\n",
       " 'not his son into the world to condemn the world;',\n",
       " 'the world; but that the world through him might be',\n",
       " 'alway ready.  7:7 the world cannot hate you; but',\n",
       " 'and i speak to the world those things which i',\n",
       " 'heareth.  9:32 since the world began was it not',\n",
       " 'ye prevail nothing? behold, the world is gone after him.',\n",
       " 'hateth his life in this world shall keep it unto',\n",
       " 'shall the prince of this world be cast out. ',\n",
       " 'should depart out of this world unto the father, having',\n",
       " 'spirit of truth; whom the world cannot receive, because it',\n",
       " 'a little while, and the world seeth me no more;',\n",
       " 'unto you: not as the world giveth, give i unto',\n",
       " 'for the prince of this world cometh, and hath nothing',\n",
       " ' 14:31 but that the world may know that i',\n",
       " 'another.  15:18 if the world hate you, ye know',\n",
       " 'were of the world, the world would love his own:',\n",
       " 'of the world, therefore the world hateth you.  15:20',\n",
       " 'come, he will reprove the world of sin, and of',\n",
       " 'because the prince of this world is judged.  16:12',\n",
       " 'weep and lament, but the world shall rejoice: and ye',\n",
       " 'have peace.  in the world ye shall have tribulation:',\n",
       " 'had with thee before the world was.  17:6 i',\n",
       " 'them thy word; and the world hath hated them, because',\n",
       " 'one in us: that the world may believe that thou',\n",
       " 'in one; and that the world may know that thou',\n",
       " '17:25 o righteous father, the world hath not known thee:',\n",
       " 'i suppose that even the world itself could not contain',\n",
       " 'his holy prophets since the world began.  3:22 for',\n",
       " 'these that have turned the world upside down are come',\n",
       " '17:24 god that made the world and all things therein,',\n",
       " 'which he will judge the world in righteousness by that',\n",
       " 'whom all asia and the world worshippeth.  19:28 and',\n",
       " 'from the creation of the world are clearly seen, being',\n",
       " 'be stopped, and all the world may become guilty before',\n",
       " 'was kept secret since the world began, 16:26 but now',\n",
       " 'the wisdom of god the world by wisdom knew not',\n",
       " 'the foolish things of the world to confound the wise;',\n",
       " 'the weak things of the world to confound the things',\n",
       " 'which god ordained before the world unto our glory: 2:8',\n",
       " 'of the princes of this world knew: for had they',\n",
       " 'for the wisdom of this world is foolishness with god.',\n",
       " 'the world? and if the world shall be judged by',\n",
       " 'for the fashion of this world passeth away.  7:32',\n",
       " 'eat no flesh while the world standeth, lest i make',\n",
       " 'whom the ends of the world are come.  10:12',\n",
       " 'whom the god of this world hath blinded the minds',\n",
       " 'was in christ, reconciling the world unto himself, not imputing',\n",
       " 'but the sorrow of the world worketh death.  7:11',\n",
       " 'jesus christ, by whom the world is crucified unto me,',\n",
       " 'from the beginning of the world hath been hid in',\n",
       " 'christ jesus throughout all ages, world without end. amen. ',\n",
       " 'christ jesus came into the world to save sinners; of',\n",
       " 'in christ jesus before the world began, 1:10 but is',\n",
       " 'cannot lie, promised before the world began; 1:3 but hath',\n",
       " 'not put in subjection the world to come, whereof we',\n",
       " 'and the powers of the world to come, 6:6 if',\n",
       " 'in the end of the world hath he appeared to',\n",
       " 'tormented; 11:38 (of whom the world was not worthy:) they',\n",
       " 'chosen the poor of this world rich in faith, and',\n",
       " 'tongue is a fire, a world of iniquity: so is',\n",
       " 'that the friendship of the world is enmity with god?',\n",
       " 'be a friend of the world is the enemy of',\n",
       " 'corruption that is in the world through lust.  1:5',\n",
       " 'in the flood upon the world of the ungodly; 2:6',\n",
       " 'escaped the pollutions of the world through the knowledge of',\n",
       " 'the water: 3:6 whereby the world that then was, being',\n",
       " 'world.  2:17 and the world passeth away, and the',\n",
       " 'sons of god: therefore the world knoweth us not, because',\n",
       " 'not, my brethren, if the world hate you.  3:14',\n",
       " 'of the world, and the world heareth them.  4:6',\n",
       " 'of god, and the whole world lieth in wickedness. ',\n",
       " 'saying, the kingdoms of this world are become the kingdoms',\n",
       " 'was healed: and all the world wondered after the beast.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at what the algorithm has found\n",
    "concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how many instances of just the word \"world\" were found\n",
    "len(concordance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in the cell below, modify the code to search for a different word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2303"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# searching for the word \"god\" instead\n",
    "concordance = []\n",
    "for i, val in enumerate(bible):\n",
    "    if val == \"god\":\n",
    "        concordance.append(str(' '.join(bible[i-5:i+5])))\n",
    "\n",
    "# counting the number of occurences\n",
    "len(concordance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nltk package has the full text of several other classic books. You can see what they are called by running the command in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn!\n",
    "\n",
    "Here are a some more things you can try. In each case, I have given you a little bit of starter code to get you going, but the cells will not run without some additional code from you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Challenge 1: build your own concordance\n",
    "\n",
    "Pick a different book and a different word, or pair of words. Copy and paste from the code above to write some Python code that searches the book of your choice for the word or pair of words of your choice. Put this code in the cell below. By the way, some of the texts use the characters `\\r` for \"carriage return\" instead of `\\n` for \"newline\". You can remove these the same way that you remove the `\\n` characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Searching for instances of \"white whale\" in the Moby Dick book\n",
    "\n",
    "# Create a variable called \"moby_dick\"\n",
    "moby_dick = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')\n",
    "\n",
    "# make all characters lowercase\n",
    "moby_dick = moby_dick.lower()\n",
    "\n",
    "# remove the \"\\n\" characters\n",
    "moby_dick = moby_dick.replace('\\n', ' ')\n",
    "\n",
    "# remove the \"\\r\" characters\n",
    "moby_dick = moby_dick.replace('\\r', ' ')\n",
    "\n",
    "# split up the text into a long list of individual words\n",
    "moby_dick = moby_dick.split(' ')\n",
    "\n",
    "# searching for the words \"white whale\"\n",
    "concordance = []\n",
    "for i, val in enumerate(moby_dick):\n",
    "    if val == \"whale\":\n",
    "        if moby_dick[i-1] == \"white\":\n",
    "            concordance.append(str(' '.join(moby_dick[i-5:i+5])))\n",
    "\n",
    "# counting the number of occurences\n",
    "len(concordance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2: compare lengths of books\n",
    "\n",
    "We can use the command `len` to find how many items there are in a list. E.g., to find the number of words in the list called `bible`, above, we can write: `len(bible)`. \n",
    "\n",
    "Use the starter code below to find out which book in the books included in `nltk` has the most words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austen-emma.txt 164457\n",
      "austen-persuasion.txt 86270\n",
      "austen-sense.txt 123514\n",
      "bible-kjv.txt 848001\n",
      "blake-poems.txt 8886\n",
      "bryant-stories.txt 54942\n",
      "burgess-busterbrown.txt 17976\n",
      "carroll-alice.txt 28387\n",
      "chesterton-ball.txt 86481\n",
      "chesterton-brown.txt 80382\n",
      "chesterton-thursday.txt 59297\n",
      "edgeworth-parents.txt 195982\n",
      "melville-moby_dick.txt 243947\n",
      "milton-paradise.txt 91832\n",
      "shakespeare-caesar.txt 23339\n",
      "shakespeare-hamlet.txt 33477\n",
      "shakespeare-macbeth.txt 20164\n",
      "whitman-leaves.txt 138730\n"
     ]
    }
   ],
   "source": [
    "# solution 1: print all the titles and numbers of words\n",
    "# starter code:\n",
    "\n",
    "books = nltk.corpus.gutenberg.fileids()\n",
    "\n",
    "for title in books:\n",
    "    book = nltk.corpus.gutenberg.raw(title)\n",
    "    book = book.lower()\n",
    "    book = book.replace('\\n', ' ')\n",
    "    book = book.replace('\\r', ' ')\n",
    "    book = book.split(' ')\n",
    "    print(title, len(book))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output above, the bible seems to have the most words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more advanced, for those with some Python experience, or those who want to google around..\n",
    "# solution 2: make a list of titles and a list of wordcounts, zip them together, then sort them based on wordcount\n",
    "# starter code:\n",
    "\n",
    "books = nltk.corpus.gutenberg.fileids()\n",
    "\n",
    "titles = []\n",
    "numwords = []\n",
    "for title in books:\n",
    "    book = nltk.corpus.gutenberg.raw(title)\n",
    "    book = book.lower()\n",
    "    book = book.replace('\\n', ' ')\n",
    "    book = book.replace('\\r', ' ')\n",
    "    book = book.split(' ')\n",
    "    # adding the title to a list\n",
    "    titles.append(title)\n",
    "    # adding the word count to a list\n",
    "    numwords.append(len(book))\n",
    "\n",
    "# zipping together the two list\n",
    "zipped_list = list(zip(numwords, titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(848001, 'bible-kjv.txt'),\n",
       " (243947, 'melville-moby_dick.txt'),\n",
       " (195982, 'edgeworth-parents.txt'),\n",
       " (164457, 'austen-emma.txt'),\n",
       " (138730, 'whitman-leaves.txt'),\n",
       " (123514, 'austen-sense.txt'),\n",
       " (91832, 'milton-paradise.txt'),\n",
       " (86481, 'chesterton-ball.txt'),\n",
       " (86270, 'austen-persuasion.txt'),\n",
       " (80382, 'chesterton-brown.txt'),\n",
       " (59297, 'chesterton-thursday.txt'),\n",
       " (54942, 'bryant-stories.txt'),\n",
       " (33477, 'shakespeare-hamlet.txt'),\n",
       " (28387, 'carroll-alice.txt'),\n",
       " (23339, 'shakespeare-caesar.txt'),\n",
       " (20164, 'shakespeare-macbeth.txt'),\n",
       " (17976, 'burgess-busterbrown.txt'),\n",
       " (8886, 'blake-poems.txt')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting the zipped_list in descending order and printing\n",
    "sorted(zipped_list, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the bible has the most words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3: what are the most frequent words?\n",
    "\n",
    "`nltk` has a built-in function called `FreqDist` which counts up how many times each word in a text occurs. So, if you have a list called `words` which contains all the words in a book, you can find the frequencies of all of them by writing `freq = nltk.FreqDist(words)`. You can then get the e.g. ten most common words by writing `freq.most_common(10)`. What are the ten most common words in Jane Austen's \"Emma\"? What about Herman Melville's \"Moby Dick\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 6290),\n",
       " ('the', 5120),\n",
       " ('to', 5079),\n",
       " ('and', 4445),\n",
       " ('of', 4196),\n",
       " ('a', 3055),\n",
       " ('i', 2602),\n",
       " ('was', 2302),\n",
       " ('she', 2169),\n",
       " ('in', 2091)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding ten most common words in \"Emma\"\n",
    "book = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
    "words = book.lower()\n",
    "words = words.replace('\\n', ' ')\n",
    "words = words.replace('\\r', ' ')\n",
    "words = words.split(' ')\n",
    "emma_freq = nltk.FreqDist(words)\n",
    "emma_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 31917),\n",
       " ('the', 14226),\n",
       " ('of', 6545),\n",
       " ('and', 6238),\n",
       " ('a', 4597),\n",
       " ('to', 4518),\n",
       " ('in', 4058),\n",
       " ('that', 2744),\n",
       " ('his', 2485),\n",
       " ('it', 1765)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding ten most common words in \"Moby Dick\"\n",
    "moby_dick_freq = nltk.FreqDist(moby_dick) # reusing variable from earlier\n",
    "moby_dick_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4: Remove stopwords\n",
    "\n",
    "Often, the most frequent words are not the most interesting ones. Words like \"a\" and \"the\" are so common in English, that they don't really tell us much about the text. That is why we often remove \"stopwords\", that is, a list of the most common words in English, before e.g. counting frequencies. There are several of these lists available, in [English]((https://gist.github.com/sebleier/554280)) as well as other languages, such as [Danish](https://gist.github.com/berteltorp/0cf8a0c7afea7f25ed754f24cfc2467b). Below is some starter code to remove stopwords. Use these snippets to see what the most common words in Emma and Moby Dick are after removing these most common words.\n",
    "\n",
    "Hint: In Moby Dick, you will also have to remove the string `\\r`, in addition to removing `\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of stopwords\n",
    "\n",
    "stopwords = [\"\", \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mr.', 1097),\n",
       " ('could', 800),\n",
       " ('would', 795),\n",
       " ('mrs.', 675),\n",
       " ('miss', 568),\n",
       " ('must', 543),\n",
       " ('emma', 481),\n",
       " ('much', 427),\n",
       " ('every', 425),\n",
       " ('said', 392)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding ten most common words in \"Emma\" w/o stopwords\n",
    "book = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
    "words = book.lower()\n",
    "words = words.replace('\\n', ' ')\n",
    "words = words.replace('\\r', ' ')\n",
    "words = words.split(' ')\n",
    "words = [word for word in words if word not in stopwords] # code to remove stopwords\n",
    "emma_freq = nltk.FreqDist(words) # finding each word freq\n",
    "emma_freq.most_common(10) # printing top ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('one', 779),\n",
       " ('like', 564),\n",
       " ('upon', 556),\n",
       " ('whale', 528),\n",
       " ('old', 425),\n",
       " ('would', 416),\n",
       " ('though', 311),\n",
       " ('great', 292),\n",
       " ('still', 282),\n",
       " ('seemed', 273)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding ten most common words in \"Moby Dick\"\n",
    "words = moby_dick\n",
    "words = [word for word in words if word not in stopwords] # code to remove stopwords\n",
    "moby_dick_freq = nltk.FreqDist(words) # finding each word freq\n",
    "moby_dick_freq.most_common(10) # printing top ten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 03: Fun with `pandas`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some exercises to get you working with `pandas` to manipulate data. As always, get as far as you can, and ask for help when you need it! Your teacher (me), you instructor, and your classmates are all here to help each other get better at coding. Getting the code to work is important, but do also take the time to make sure you understand what the commands are doing. This time, (with the exception of the Stroop challenge), all I've given you is the code to download the data. Then you are on your own. For the Stroop challenge, I gave the you code for the first step—after that, it's up to you :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music sales challenge\n",
    "\n",
    "Write a script that:\n",
    "\n",
    "1. Combines the tables of best-selling physical singles and best-selling digital singles on the Wikipedia page \"List_of_best-selling_singles\"\n",
    "2. Adds a column which marks whether each row is from the list of physical singles or digital singles\n",
    "3. Outputs the artist and single name for the year you were born. If there is no entry for that year, take the closest year after you were born.\n",
    "4. Outputs the artist and single name for the year you were 15 years old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lxml\n",
    "%pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries from my birthyear, 1997, include Elton John with \"Something About the Way You Look Tonight\"/\"Candle in the Wind 1997\"\n",
      "Entries from my birthyear, 1997, include Celine Dion with \"My Heart Will Go On\"\n",
      "Entries from the year I was 15 include Imagine Dragons with \"Radioactive\"\n",
      "Entries from the year I was 15 include Macklemore and Ryan Lewis featuring Wanz with \"Thrift Shop\"\n"
     ]
    }
   ],
   "source": [
    "rawdata = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_best-selling_singles\")\n",
    "df1 = rawdata[0] # physical, 15 million physical copies or more\n",
    "df1['Type'] = 'physical' # adding new col with type\n",
    "df2 = rawdata[1] # physical, 10–14.9 million copies\n",
    "df2['Type'] = 'physical'\n",
    "df3 = rawdata[3] # digital, 15 million digital copies or more\n",
    "df3['Type'] = 'digital'\n",
    "df4 = rawdata[4] # digital, 10–14.99 million copies\n",
    "df4['Type'] = 'digital'\n",
    "\n",
    "# combining\n",
    "df = pd.concat([df1, df2, df3, df4])\n",
    "\n",
    "# im born in 1997, so making a new df with those entries\n",
    "df_1997 = df[df['Released'] == 1997]\n",
    "\n",
    "# printing content of 1997 list in prose\n",
    "for i in range(len(df_1997)):\n",
    "    artist = df_1997.iloc[i,0]\n",
    "    single = df_1997.iloc[i,1]\n",
    "    print('Entries from my birthyear, 1997, include', artist, 'with', single)\n",
    "\n",
    "# adding 15 years to 1997, and making a new df with those entries\n",
    "df_age_15 = df[df['Released'] == 1997+15]\n",
    "\n",
    "# printing content of age_15 list in prose\n",
    "for i in range(len(df_age_15)):\n",
    "    artist = df_age_15.iloc[i,0]\n",
    "    single = df_age_15.iloc[i,1]\n",
    "    print('Entries from the year I was 15 include', artist, 'with', single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Space challenge\n",
    "\n",
    "1. Make a single dataframe that combines the space missions from the 1950's to the 2020's\n",
    "2. Write a script that returns the year with the most launches\n",
    "3. Write a script that returns the most common month for launches\n",
    "4. Write a script that ranks the months from most launches to fewest launches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The year with the most launches was 1965 with 12 launches.\n",
      "The month with the most launches was November with 30 launches.\n",
      "Ranking the months from most launches to fewest launches:\n",
      "November\n",
      "August\n",
      "October\n",
      "September\n",
      "July\n",
      "January\n",
      "December\n",
      "May\n",
      "March\n",
      "February\n",
      "June\n",
      "April\n"
     ]
    }
   ],
   "source": [
    "rawdata = pd.read_html(\"https://en.wikipedia.org/wiki/Timeline_of_Solar_System_exploration\")\n",
    "\n",
    "# combining df's\n",
    "df = pd.DataFrame() # preparing df\n",
    "for i in range(8): # looping through the 8 df on wiki page\n",
    "    df = pd.concat([df,rawdata[i]]) # adding the content of iteration to main df\n",
    "\n",
    "# script that returns year with most launches\n",
    "df['Launch year'] = df['Launch date'].str[-4:] # making new col with launch year -> which is the first four characters from the right\n",
    "grouped_df = df.groupby('Launch year').count().reset_index() # grouping by launch year and counting number of entries in each group\n",
    "grouped_df = grouped_df.sort_values(by = ['Mission name'], ascending = False) # sorting from highest to lowest count\n",
    "print('The year with the most launches was', grouped_df.iloc[0]['Launch year'], 'with', grouped_df.iloc[0]['Description'], 'launches.') # printing top result in prose\n",
    "\n",
    "# script that returns most common month for launches\n",
    "df['Launch date'] = pd.to_datetime(df['Launch date']) # formatting launch date as datetime\n",
    "df['Launch month'] = df['Launch date'].dt.strftime('%B') # extracting month from Launch date to new col\n",
    "grouped_df = df.groupby('Launch month').count().reset_index() # grouping by launch month and counting number of entries in each group\n",
    "grouped_df = grouped_df.sort_values(by = ['Mission name'], ascending = False) # sorting from highest to lowest count\n",
    "print('The month with the most launches was', grouped_df.iloc[0]['Launch month'], 'with', grouped_df.iloc[0]['Description'], 'launches.') # printing top result in prose\n",
    "\n",
    "# script that ranks the months from most launches to fewest launches\n",
    "print('Ranking the months from most launches to fewest launches:')\n",
    "for i in range(len(grouped_df)):\n",
    "    print(grouped_df.iloc[i]['Launch month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervillain challenge\n",
    "\n",
    "1. Write a script that combines the tables showing supervillain debuts from the 30's through the 2010's\n",
    "2. Write a script that ranks each decade in terms of how many supervillains debuted in that decade\n",
    "3. Write a script that ranks the different comics companies in terms of how many supervillains they have, and display the results in a nice table (pandas dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decade</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1980</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1990</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1940</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1930</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Decade  Count\n",
       "3    1960    228\n",
       "4    1970     97\n",
       "5    1980     92\n",
       "6    1990     84\n",
       "7    2000     49\n",
       "1    1940     47\n",
       "2    1950     26\n",
       "8    2010      9\n",
       "0    1930      4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rawdata = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_comic_book_supervillain_debuts\")\n",
    "\n",
    "df = pd.DataFrame() # preparing df\n",
    "Decade = 1930 # preparing start value for decade variable\n",
    "\n",
    "# script that combines tables\n",
    "for i in range(3,12): # looping through item 3-11 on wiki page\n",
    "    rawdata[i]['Decade'] = Decade # storing decade variable in new col\n",
    "    df = pd.concat([df,rawdata[i]]) # adding the content of iteration to main df\n",
    "    Decade = Decade + 10 # updating decade variable\n",
    "\n",
    "# script that ranks each decade by number of debuting supervillains\n",
    "grouped_df = df.groupby('Decade').count().reset_index() # grouping by decade and counting number of entries in each group\n",
    "nice_df = grouped_df[['Decade','Year Debuted']].copy().rename(columns={'Decade':'Decade','Year Debuted':'Count'}) # copying Decade and count to new df\n",
    "nice_df = nice_df.sort_values(by = ['Count'], ascending = False) # sorting from highest to lowest count\n",
    "nice_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DC</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Marvel</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fawcett Comics/DC</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Image</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Disney/Hyperion</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Marvel/Timely</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eternity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comico</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Image Comics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lev Gleason Publications</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mirage</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company  Count\n",
       "1                         DC    338\n",
       "9                     Marvel    264\n",
       "5          Fawcett Comics/DC      6\n",
       "2                 Dark Horse      5\n",
       "6                      Image      5\n",
       "3            Disney/Hyperion      4\n",
       "10             Marvel/Timely      4\n",
       "4                   Eternity      3\n",
       "0                     Comico      1\n",
       "7               Image Comics      1\n",
       "8   Lev Gleason Publications      1\n",
       "11                    Mirage      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# script that ranks comic companies by number of supervillains as pd df\n",
    "grouped_df = df.groupby('Company').count().reset_index() # grouping by company and counting number of entries in each group\n",
    "nice_df = grouped_df[['Company','Year Debuted']].copy().rename(columns={'Company':'Company','Year Debuted':'Count'}) # copying Company and count to new df\n",
    "nice_df = nice_df.sort_values(by = ['Count'], ascending = False) # sorting from highest to lowest count\n",
    "nice_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stroop challenge\n",
    "\n",
    "Every year between 2015 and 2021, the students in my Language, Cognition, and the Brain course participated in a version of the Stroop task. Using a stopwatch (ok, using their phones), they recorded how fast they could say a list of things (either reading or naming colors or color words). The column names mean \"Reading with No Interference\", \"Naming with Interference\", \"Naming with No Interference\", and \"Reading with Interference\". The times are in seconds.\n",
    "\n",
    "### Stroop challenge 1: \n",
    "Transform these data from wide format to long format, so that the result is a dataframe with\n",
    "- 1 column named \"Participant_id\" with a unique number for each participant (you can use the row indices)\n",
    "- 1 column named \"Year\" with the year data\n",
    "- 1 column named \"Task\" that shows which task they were doing\n",
    "- 1 column named \"RT\" that shows their response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_id</th>\n",
       "      <th>Year</th>\n",
       "      <th>Task</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Reading_NoInt</td>\n",
       "      <td>4.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Reading_NoInt</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>Reading_NoInt</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>Reading_NoInt</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>Reading_NoInt</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>2021</td>\n",
       "      <td>Reading_NoInt</td>\n",
       "      <td>5.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>2021</td>\n",
       "      <td>Reading_NoInt</td>\n",
       "      <td>4.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Naming_Int</td>\n",
       "      <td>6.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Naming_Int</td>\n",
       "      <td>7.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>Naming_Int</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Participant_id  Year           Task    RT\n",
       "0                 0  2015  Reading_NoInt  4.16\n",
       "1                 1  2015  Reading_NoInt  4.35\n",
       "2                 2  2015  Reading_NoInt  3.60\n",
       "3                 3  2015  Reading_NoInt  3.90\n",
       "4                 4  2015  Reading_NoInt  4.22\n",
       "..              ...   ...            ...   ...\n",
       "180             180  2021  Reading_NoInt  5.16\n",
       "181             181  2021  Reading_NoInt  4.27\n",
       "182               0  2015     Naming_Int  6.76\n",
       "183               1  2015     Naming_Int  7.73\n",
       "184               2  2015     Naming_Int  7.00\n",
       "\n",
       "[185 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/ethanweed/Stroop/master/Stroop-raw-over-the-years.csv\")\n",
    "# Make a new column using the dataframe indices as particpant numbers\n",
    "df.index.name = 'Participant_id'\n",
    "df = df.reset_index()\n",
    "\n",
    "# transforming from wide to long format\n",
    "df_long = pd.melt(df, id_vars=[ 'Participant_id', 'Year']) # transforming to long format\n",
    "df_long = df_long.rename(columns={'Participant_id':'Participant_id','Year':'Year', 'variable': 'Task', 'value': 'RT'}) # renaming headers\n",
    "df_long.head(185) # inspecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stroop challenge 2 (Advanced!!!):\n",
    "\n",
    "Make a new dataframe which shows the mean response time (in seconds) for each task for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Year</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naming_Int</td>\n",
       "      <td>2015</td>\n",
       "      <td>8.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naming_Int</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.859268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naming_Int</td>\n",
       "      <td>2017</td>\n",
       "      <td>9.311765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naming_Int</td>\n",
       "      <td>2018</td>\n",
       "      <td>9.372667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naming_Int</td>\n",
       "      <td>2019</td>\n",
       "      <td>9.536087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naming_Int</td>\n",
       "      <td>2020</td>\n",
       "      <td>9.740833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Naming_Int</td>\n",
       "      <td>2021</td>\n",
       "      <td>10.105484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naming_NoInt</td>\n",
       "      <td>2015</td>\n",
       "      <td>5.123571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Naming_NoInt</td>\n",
       "      <td>2016</td>\n",
       "      <td>5.405610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Naming_NoInt</td>\n",
       "      <td>2017</td>\n",
       "      <td>5.771176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Naming_NoInt</td>\n",
       "      <td>2018</td>\n",
       "      <td>5.298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Naming_NoInt</td>\n",
       "      <td>2019</td>\n",
       "      <td>6.345652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Naming_NoInt</td>\n",
       "      <td>2020</td>\n",
       "      <td>5.962500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Naming_NoInt</td>\n",
       "      <td>2021</td>\n",
       "      <td>6.387742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Reading_Int</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.446429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Reading_Int</td>\n",
       "      <td>2016</td>\n",
       "      <td>5.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Reading_Int</td>\n",
       "      <td>2017</td>\n",
       "      <td>5.492353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Reading_Int</td>\n",
       "      <td>2018</td>\n",
       "      <td>4.938667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Reading_Int</td>\n",
       "      <td>2019</td>\n",
       "      <td>6.090870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Reading_Int</td>\n",
       "      <td>2020</td>\n",
       "      <td>4.956667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Reading_Int</td>\n",
       "      <td>2021</td>\n",
       "      <td>7.038065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Reading_NoInt</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.951429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Reading_NoInt</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.076098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Reading_NoInt</td>\n",
       "      <td>2017</td>\n",
       "      <td>4.414412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Reading_NoInt</td>\n",
       "      <td>2018</td>\n",
       "      <td>3.886000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Reading_NoInt</td>\n",
       "      <td>2019</td>\n",
       "      <td>4.935652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Reading_NoInt</td>\n",
       "      <td>2020</td>\n",
       "      <td>4.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Reading_NoInt</td>\n",
       "      <td>2021</td>\n",
       "      <td>4.842581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Task  Year         RT\n",
       "0      Naming_Int  2015   8.617143\n",
       "1      Naming_Int  2016   8.859268\n",
       "2      Naming_Int  2017   9.311765\n",
       "3      Naming_Int  2018   9.372667\n",
       "4      Naming_Int  2019   9.536087\n",
       "5      Naming_Int  2020   9.740833\n",
       "6      Naming_Int  2021  10.105484\n",
       "7    Naming_NoInt  2015   5.123571\n",
       "8    Naming_NoInt  2016   5.405610\n",
       "9    Naming_NoInt  2017   5.771176\n",
       "10   Naming_NoInt  2018   5.298000\n",
       "11   Naming_NoInt  2019   6.345652\n",
       "12   Naming_NoInt  2020   5.962500\n",
       "13   Naming_NoInt  2021   6.387742\n",
       "14    Reading_Int  2015   4.446429\n",
       "15    Reading_Int  2016   5.340000\n",
       "16    Reading_Int  2017   5.492353\n",
       "17    Reading_Int  2018   4.938667\n",
       "18    Reading_Int  2019   6.090870\n",
       "19    Reading_Int  2020   4.956667\n",
       "20    Reading_Int  2021   7.038065\n",
       "21  Reading_NoInt  2015   3.951429\n",
       "22  Reading_NoInt  2016   4.076098\n",
       "23  Reading_NoInt  2017   4.414412\n",
       "24  Reading_NoInt  2018   3.886000\n",
       "25  Reading_NoInt  2019   4.935652\n",
       "26  Reading_NoInt  2020   4.395000\n",
       "27  Reading_NoInt  2021   4.842581"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouped_df = df_long.groupby(['Task', 'Year'])['RT'].mean().reset_index()\n",
    "grouped_df"
   ]
  }
 ],
 "metadata": {
  "author": "Julie Bang Mikkelsen (AU718507)",
  "date": "January 7th, 2025",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "title": "Assignment 1"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
